{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 1: Python Basics\n",
    "\n",
    "This first  exercise sheet tests the basic functionalities of the Python programming language in the context of a simple prediction task. We consider the problem of predicting health risk of subjects from personal data and habits. We first use for this task a decision tree\n",
    "\n",
    "![](tree.png)\n",
    "\n",
    "adapted from the webpage http://www.refactorthis.net/post/2013/04/10/Machine-Learning-tutorial-How-to-create-a-decision-tree-in-RapidMiner-using-the-Titanic-passenger-data-set.aspx. For this exercise sheet, you are required to use only pure Python, and to not import any module, including numpy. In exercise sheet 2, the nearest neighbor part of this exercise sheet will be revisited with numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying a single instance (15 P)\n",
    "\n",
    "* Create a function that takes as input a tuple containing values for attributes (smoker,age,diet), and computes the output of the decision tree.\n",
    "* Test your function on the tuple `('yes',31,'good')`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('yes', 31, 'good'), 'more')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exercise1(x):\n",
    "        result = []\n",
    "        if x[0] == 'yes':\n",
    "            if x[1] > 29.5:\n",
    "                decision = 'more'\n",
    "            else:\n",
    "                decision = 'less'\n",
    "        else:\n",
    "            if x[2] == 'poor':\n",
    "                decision = 'more'\n",
    "            else:\n",
    "                decision = 'less'\n",
    "        result.append(((x[0],x[1],x[2]),decision))\n",
    "        return result\n",
    "\n",
    "exercise1(('yes',31,'good'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a dataset from a text file (10 P)\n",
    "\n",
    "The file `health-test.txt` contains several fictious records of personal data and habits.\n",
    "\n",
    "* Read the file automatically using the methods introduced during the lecture.\n",
    "* Represent the dataset as a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yes', 21, 'poor'),\n",
       " ('no', 50, 'good'),\n",
       " ('no', 23, 'good'),\n",
       " ('yes', 45, 'poor'),\n",
       " ('yes', 51, 'good'),\n",
       " ('no', 60, 'good'),\n",
       " ('no', 15, 'poor'),\n",
       " ('no', 18, 'good')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exercise2():\n",
    "    f = open('health-test.txt','r')\n",
    "    L = []\n",
    "    for line in f:\n",
    "        elem = line[:-1].split(',')\n",
    "        #L += [(elem[0],float(elem[1]),elem[2])]\n",
    "        if float(elem[1])%1 == 0:\n",
    "            age = int(elem[1])\n",
    "        else:\n",
    "            age = float(elem[1])\n",
    "        L.append((elem[0],age,elem[2])) \n",
    "    f.close()\n",
    "    return L\n",
    "\n",
    "exercise2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the decision tree to the dataset (15 P)\n",
    "\n",
    "* Apply the decision tree to all points in the dataset, and compute the percentage of them that are classified as \"more risk\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exercise3(dataSet):\n",
    "    avr = 0\n",
    "    percentage = 0\n",
    "    for j in dataSet:\n",
    "        if exercise1(j)[0][1] == 'more':\n",
    "            avr += 1\n",
    "    return (avr/(len(dataSet)))\n",
    "     \n",
    "exercise3(exercise2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from examples (10 P)\n",
    "\n",
    "Suppose that instead of relying on a fixed decision tree, we would like to use a data-driven approach where data points are classified based on a set of training observations manually labeled by experts. Such labeled dataset is available in the file `health-train.txt`. The first three columns have the same meaning than for `health-test.txt`, and the last column corresponds to the labels.\n",
    "\n",
    "* Write a procedure that reads this file and converts it into a list of pairs. The first element of each pair is a triplet of attributes, and the second element is the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('yes', 54, 'good'), 'less'),\n",
       " (('no', 55, 'good'), 'less'),\n",
       " (('no', 26, 'good'), 'less'),\n",
       " (('yes', 40, 'good'), 'more'),\n",
       " (('yes', 25, 'poor'), 'less'),\n",
       " (('no', 13, 'poor'), 'more'),\n",
       " (('no', 15, 'good'), 'less'),\n",
       " (('no', 50, 'poor'), 'more'),\n",
       " (('yes', 33, 'good'), 'more'),\n",
       " (('no', 35, 'good'), 'less'),\n",
       " (('no', 41, 'good'), 'less'),\n",
       " (('yes', 30, 'poor'), 'more'),\n",
       " (('no', 39, 'poor'), 'more'),\n",
       " (('no', 20, 'good'), 'less'),\n",
       " (('yes', 18, 'poor'), 'less'),\n",
       " (('yes', 55, 'good'), 'more')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exercise4():\n",
    "    f = open('health-train.txt','r')\n",
    "    Dtriplet = []\n",
    "    Dlabel = []\n",
    "    for line in f:\n",
    "        elem = line[:-1].split(',')\n",
    "        if float(elem[1])%1 == 0:\n",
    "            age = int(elem[1])\n",
    "        else:\n",
    "            age = float(elem[1])\n",
    "        Dtriplet.append((elem[0],age,elem[2]))\n",
    "        Dlabel.append((elem[3]))\n",
    "    f.close()\n",
    "    return(list(zip(Dtriplet, Dlabel)))\n",
    "\n",
    "exercise4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbor classifier (25 P)\n",
    "\n",
    "We consider the nearest neighbor algorithm that classifies test points following the label of the nearest neighbor in the training data. For this, we need to define a distance function between data points. We define it to be\n",
    "\n",
    "`d(a,b) = (a[0]!=b[0])+((a[1]-b[1])/50.0)**2+(a[2]!=b[2])`\n",
    "\n",
    "where `a` and `b` are two tuples corrsponding to the attributes of two data points.\n",
    "\n",
    "* Write a function that retrieves for a test point the nearest neighbor in the training set, and classifies the test point accordingly.\n",
    "* Test your function on the tuple `('yes',31,'good')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('yes', 31, 'good'), 'more')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exercise5a():\n",
    "    #distance fuction based on the assigment\n",
    "    def d(a,b):\n",
    "        return (a[0]!=b[0])+((a[1]-b[1])/50.0)**2+(a[2]!=b[2])\n",
    "\n",
    "    def getNeighbors(testPoint):\n",
    "        f = open('health-train.txt','r')\n",
    "    \n",
    "        Dtriplet = []\n",
    "        Dlabel = []\n",
    "        for line in f:\n",
    "            elem = line[:-1].split(',')\n",
    "            Dtriplet.append((elem[0],float(elem[1]),elem[2]))\n",
    "            Dlabel.append((elem[3]))\n",
    "\n",
    "        testSet = list(zip(Dtriplet, Dlabel))\n",
    "        distances = []\n",
    "        for x in range(len(testSet)):\n",
    "            dist = d(testPoint, testSet[x][0])\n",
    "            distances.append((testSet[x], dist))\n",
    "        #sort the list appended by distance and than take only the lowest distance and save it to neighbors list\n",
    "        distances.sort(key=lambda tup: tup[1])\n",
    "        neighbors = []\n",
    "        result = []\n",
    "        neighbors.append(distances[0][0])\n",
    "        result.append((testPoint,neighbors[0][1]))\n",
    "        return ((result))\n",
    "\n",
    "    return(getNeighbors(('yes',31,'good')))\n",
    "\n",
    "exercise5a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply both the decision tree and nearest neighbor classifiers on the test set, and find the data point(s) for which the two classifiers disagree, and with which probability it happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('yes', 51.0, 'good')], 0.125)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exercise5b():\n",
    "    def decisionTree(x):\n",
    "            result = []\n",
    "            if x[0] == 'yes':\n",
    "                if x[1] > 29.5:\n",
    "                    decision = 'more'\n",
    "                else:\n",
    "                    decision = 'less'\n",
    "            else:\n",
    "                if x[2] == 'poor':\n",
    "                    decision = 'more'\n",
    "                else:\n",
    "                    decision = 'less'\n",
    "            result.append((x,decision))\n",
    "            return result\n",
    "\n",
    "    #distance fuction based on the assigment\n",
    "    def d(a,b):\n",
    "        return (a[0]!=b[0])+((a[1]-b[1])/50.0)**2+(a[2]!=b[2])\n",
    "    \n",
    "    def getNeighbors(testPoint):\n",
    "        f = open('health-train.txt','r')\n",
    "    \n",
    "        Dtriplet = []\n",
    "        Dlabel = []\n",
    "        for line in f:\n",
    "            elem = line[:-1].split(',')\n",
    "            Dtriplet.append((elem[0],float(elem[1]),elem[2]))\n",
    "            Dlabel.append((elem[3]))\n",
    "\n",
    "        testSet = list(zip(Dtriplet, Dlabel))\n",
    "        distances = []\n",
    "        for x in range(len(testSet)):\n",
    "            dist = d(testPoint, testSet[x][0])\n",
    "            distances.append((testSet[x], dist))\n",
    "        #sort the list appended by distance and than take only the lowest distance and save it to neighbors list\n",
    "        distances.sort(key=lambda tup: tup[1])\n",
    "        neighbors = []\n",
    "        result = []\n",
    "        neighbors.append(distances[0][0])\n",
    "        result.append((testPoint,neighbors[0][1]))\n",
    "        f.close()\n",
    "        return ((result))\n",
    "    #testSet\n",
    "    f = open('health-test.txt','r')\n",
    "    L = []\n",
    "    for line in f:\n",
    "        elem = line[:-1].split(',')\n",
    "        L.append((elem[0],float(elem[1]),elem[2])) \n",
    "\n",
    "    L_notMatching = []\n",
    "    for line in L:\n",
    "        if decisionTree(line) != getNeighbors(line):\n",
    "            L_notMatching.append(line) \n",
    "            probability_notMatching = len(L_notMatching)/len(L)\n",
    "\n",
    "    return((L_notMatching, probability_notMatching))\n",
    "\n",
    "exercise5b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem of simple nearest neighbors is that one needs to compare the point to predict to all data points in the training set. This can be slow for datasets of thousands of points or more. Alternatively, some classifiers train a model first, and then use it to classify the data.\n",
    "\n",
    "## Nearest mean classifier (25 P)\n",
    "\n",
    "We consider one such trainable model, which operates in two steps:\n",
    "\n",
    "(1) Compute the average point for each class, (2) classify new points to be of the class whose average point is nearest to the point to predict.\n",
    "\n",
    "For this classifier, we convert the attributes smoker and diet to real values (for smoker: yes=1.0 and no=0.0, and for diet: good=0.0 and poor=1.0), and use the modified distance function:\n",
    "\n",
    "`d(a,b) = (a[0]-b[0])**2+((a[1]-b[1])/50.0)**2+(a[2]-b[2])**2`\n",
    "\n",
    "We adopt an object-oriented approach for building this classifier.\n",
    "\n",
    "* Implement the methods `train` and `predict` of the class `NearestMeanClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NearestMeanClassifier:\n",
    "    \n",
    "    # Training method that takes as input a dataset\n",
    "    # and produces two internal vectors corresponding\n",
    "    # to the mean of each class.\n",
    "    def train(self,dataset):\n",
    "        def valuate(trainPoint):\n",
    "                if trainPoint[0][0] == 'yes':\n",
    "                    smoke = 1.0\n",
    "                else:\n",
    "                    smoke = 0.0\n",
    "                age = trainPoint[0][1]\n",
    "                if trainPoint[0][2] == 'poor':\n",
    "                    diet = 1.0\n",
    "                else:\n",
    "                    diet = 0.0\n",
    "                return((smoke, age, diet), trainPoint[1])\n",
    "            \n",
    "        L_valuated = []\n",
    "        for trainPoint in dataset:\n",
    "            L_valuated.append(valuate(trainPoint))\n",
    "        \n",
    "        more_risk_data = []\n",
    "        less_risk_data = []\n",
    "        for line in L_valuated:\n",
    "            if line[1] == 'more':\n",
    "                more_risk_data.append(line[0])\n",
    "            else:\n",
    "                less_risk_data.append(line[0])\n",
    "                \n",
    "        more_risk_avg = tuple(sum(y) / len(y) for y in zip(*more_risk_data))\n",
    "        less_risk_avg = tuple(sum(y) / len(y) for y in zip(*less_risk_data))\n",
    "        self.means = ([(more_risk_avg, 'more'), (less_risk_avg, 'less')])  \n",
    "\n",
    "    # Prediction method that takes as input a new data\n",
    "    # point and predicts it to belong to the class with\n",
    "    # nearest mean.\n",
    "    def predict(self,x):\n",
    "        def valuate(trainPoint):\n",
    "            if trainPoint[0] == 'yes':\n",
    "                smoke = 1.0\n",
    "            else:\n",
    "                smoke = 0.0\n",
    "            age = trainPoint[1]\n",
    "            if trainPoint[2] == 'poor':\n",
    "                diet = 1.0\n",
    "            else:\n",
    "                diet = 0.0\n",
    "            return((smoke, age, diet))\n",
    "        def mean_dist(mean_tuple, new_tuple):\n",
    "            new_tuple = valuate(new_tuple)\n",
    "            d = (mean_tuple[0][0] - new_tuple[0]) ** 2 + ((mean_tuple[0][1] - new_tuple[1]) / 50.0) ** 2 + (mean_tuple[0][2] - new_tuple[2]) ** 2\n",
    "            return (d)\n",
    "        \n",
    "        j = ''\n",
    "        L_predict = []\n",
    "        for new_tuple in x:\n",
    "            if mean_dist(self.means[1], new_tuple) < mean_dist(self.means[0], new_tuple):\n",
    "                j = 'less'\n",
    "            else:\n",
    "                j = 'more'\n",
    "            L_predict.append((new_tuple,j))\n",
    "        return(L_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build an object of class `NearestMeanClassifier`, train it on the training data, and print the mean vector for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.5714285714285714, 37.142857142857146, 0.5714285714285714), 'more'),\n",
       " ((0.3333333333333333, 32.111111111111114, 0.2222222222222222), 'less')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exercise6a():\n",
    "    trainData = exercise4()\n",
    "    c = NearestMeanClassifier()\n",
    "    c.train(trainData)\n",
    "    return c\n",
    "    \n",
    "exercise6a().means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Predict the test data using the nearest mean classifier and print all test examples for which all three classifiers (decision tree, nearest neighbor and nearest mean) agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('no', 50, 'good'), 'less')]\n",
      "[(('no', 23, 'good'), 'less')]\n",
      "[(('yes', 45, 'poor'), 'more')]\n",
      "[(('no', 60, 'good'), 'less')]\n",
      "[(('no', 15, 'poor'), 'more')]\n",
      "[(('no', 18, 'good'), 'less')]\n"
     ]
    }
   ],
   "source": [
    "def exercise6b():\n",
    "    def decisionTree(x):\n",
    "        result = []\n",
    "        if x[0] == 'yes':\n",
    "            if x[1] > 29.5:\n",
    "                decision = 'more'\n",
    "            else:\n",
    "                decision = 'less'\n",
    "        else:\n",
    "            if x[2] == 'poor':\n",
    "                decision = 'more'\n",
    "            else:\n",
    "                decision = 'less'\n",
    "        result.append((x,decision))\n",
    "        return result\n",
    "    def d(a,b):\n",
    "        return (a[0]!=b[0])+((a[1]-b[1])/50.0)**2+(a[2]!=b[2])\n",
    "    def getNeighbors(testPoint):\n",
    "        f = open('health-train.txt','r')\n",
    "    \n",
    "        Dtriplet = []\n",
    "        Dlabel = []\n",
    "        for line in f:\n",
    "            elem = line[:-1].split(',')\n",
    "            Dtriplet.append((elem[0],float(elem[1]),elem[2]))\n",
    "            Dlabel.append((elem[3]))\n",
    "\n",
    "        testSet = list(zip(Dtriplet, Dlabel))\n",
    "        distances = []\n",
    "        for x in range(len(testSet)):\n",
    "            dist = d(testPoint, testSet[x][0])\n",
    "            distances.append((testSet[x], dist))\n",
    "        #sort the list appended by distance and than take only the lowest distance and save it to neighbors list\n",
    "        distances.sort(key=lambda tup: tup[1])\n",
    "        neighbors = []\n",
    "        result = []\n",
    "        neighbors.append(distances[0][0])\n",
    "        result.append((testPoint,neighbors[0][1]))\n",
    "        return ((result))\n",
    " \n",
    "    L = exercise2()\n",
    "    c = exercise6a()\n",
    "\n",
    "    for x in range(len(L)):\n",
    "        nm = c.predict(L)[x][1]\n",
    "        nn = getNeighbors(L[x])\n",
    "        dt = decisionTree(L[x])\n",
    "        \n",
    "        if nn[0][1] == dt[0][1] == nm:\n",
    "            print(dt)\n",
    "        \n",
    "            \n",
    "\n",
    "    \n",
    "exercise6b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
